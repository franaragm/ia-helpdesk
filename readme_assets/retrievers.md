# ðŸ§  Idea central (antes del detalle)

Tu sistema responde a esta pregunta implÃ­cita:

> **â€œÂ¿CÃ³mo recupero los fragmentos mÃ¡s Ãºtiles, variados y robustos posibles para una pregunta legal?â€**

La respuesta es:

1. **Primero**: buscar fragmentos relevantes
2. **DespuÃ©s**: evitar fragmentos redundantes
3. **DespuÃ©s**: reformular la pregunta para no perder informaciÃ³n
4. **Opcionalmente**: combinar estrategias distintas

Cada retriever resuelve **un problema distinto**.

---

# 1ï¸âƒ£ VectorStore Retriever (el mÃ¡s bÃ¡sico)

```python
vectorstore.as_retriever(search_type="similarity", k=SEARCH_K)
```

### QuÃ© hace

* Busca los `K` fragmentos **mÃ¡s parecidos semÃ¡nticamente** a la pregunta.
* Usa distancia de embeddings (coseno, L2, etc.).

### Problema que tiene

âŒ Si hay muchos fragmentos parecidos:

* Te devuelve **trozos casi idÃ©nticos**
* Ignora otros aspectos relevantes

Ejemplo:

```
Contrato A: â€œEl arrendatario es Juan PÃ©rezâ€¦â€
Contrato B: â€œEl arrendatario es Juan PÃ©rezâ€¦â€
Contrato C: â€œDuraciÃ³n del contrato: 12 mesesâ€¦â€
```

Si preguntas:

> â€œÂ¿QuiÃ©n es el arrendatario?â€

Similarity puede devolver A y B â†’ **redundancia**

---

# 2ï¸âƒ£ MMR Retriever (Maximal Marginal Relevance)

```python
base_retriever = vectorstore.as_retriever(
    search_type="mmr",
    k=SEARCH_K,
    fetch_k=MMR_FETCH_K,
    lambda_mult=MMR_DIVERSITY_LAMBDA,
)
```

### QuÃ© hace

MMR responde a:

> â€œDame fragmentos relevantes, pero **no repetidos**â€

### CÃ³mo funciona

1. Busca `fetch_k` candidatos relevantes
2. Selecciona `k` fragmentos:

   * relevantes **y**
   * diferentes entre sÃ­

### Resultado

* Menos redundancia
* MÃ¡s cobertura de informaciÃ³n

ðŸ’¡ **Por eso este es tu â€œbase_retrieverâ€**
Es una **mejora directa** sobre similarity.

---

# 3ï¸âƒ£ MultiQueryRetriever (el salto de calidad)

```python
mmr_multi_retriever = MultiQueryRetriever.from_llm(
    retriever=base_retriever,
    llm=llm_queries,
)
```

### Problema que resuelve

Las personas preguntan **mal** o **de forma parcial**.

Ejemplo:

> â€œÂ¿QuiÃ©n vive en el piso?â€

Pero el contrato dice:

* arrendatario
* inquilino
* parte arrendataria

### QuÃ© hace MultiQuery

1. Usa un LLM para generar **3 versiones alternativas** de la pregunta
2. Ejecuta el retriever (MMR) **para cada versiÃ³n**
3. Une y deduplica los resultados

Ejemplo:

```
Original: Â¿QuiÃ©n vive en el piso?
Variantes:
- Â¿QuiÃ©n es el arrendatario del inmueble?
- Â¿QuiÃ©n figura como inquilino en el contrato?
- Â¿QuÃ© persona ocupa la vivienda?
```

ðŸ‘‰ Esto **multiplica la capacidad de recall** (no perder info).

---

### Por quÃ© MultiQuery usa MMR y no similarity

Porque:

* Ya estÃ¡s ejecutando **varias bÃºsquedas**
* Sin MMR, tendrÃ­as **muchÃ­sima redundancia**
* MMR filtra mejor cada bÃºsqueda

ðŸ“Œ **MMR = base sÃ³lida**
ðŸ“Œ **MultiQuery = expansiÃ³n inteligente**

---

# 4ï¸âƒ£ Similarity Retriever (por quÃ© sigue existiendo)

```python
similarity_retriever = vectorstore.as_retriever(
    search_type="similarity",
    k=SEARCH_K,
)
```

### Â¿No era malo similarity?

No. Es:

* Muy preciso
* Muy directo
* Muy rÃ¡pido

Pero:

* Puede ser demasiado estrecho

### Por quÃ© lo conservas

Porque a veces:

* La pregunta estÃ¡ **perfectamente formulada**
* Similarity devuelve el fragmento exacto
* MultiQuery + MMR puede â€œdiluirâ€ eso

---

# 5ï¸âƒ£ EnsembleRetriever (la combinaciÃ³n final)

```python
EnsembleRetriever(
    retrievers=[mmr_multi_retriever, similarity_retriever],
    weights=[0.7, 0.3],
)
```

### QuÃ© hace

Combina resultados de **distintas estrategias**.

PiÃ©nsalo asÃ­:

| Estrategia       | Rol                    |
| ---------------- | ---------------------- |
| MultiQuery + MMR | Explorador inteligente |
| Similarity       | Francotirador preciso  |

### Pesos

```python
weights=[0.7, 0.3]
```

* 70% confianza en exploraciÃ³n semÃ¡ntica
* 30% confianza en match directo

### similarity_threshold

Evita meter basura irrelevante.

---

# 6ï¸âƒ£ Diagrama mental completo

```
Pregunta
  â”‚
  â”œâ”€ Similarity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                             â”œâ”€ Ensemble â”€â–º docs finales
  â””â”€ MultiQuery
        â”œâ”€ variante 1 â”€â–º MMR â”€â”
        â”œâ”€ variante 2 â”€â–º MMR â”€â”¤
        â””â”€ variante 3 â”€â–º MMR â”€â”˜
```

---

# 7ï¸âƒ£ Resumen ultra claro

| Componente          | Por quÃ© existe                          |
| ------------------- | --------------------------------------- |
| SimilarityRetriever | PrecisiÃ³n directa                       |
| MMRRetriever        | Evita duplicados                        |
| MultiQueryRetriever | No perder informaciÃ³n por mala pregunta |
| EnsembleRetriever   | Combina precisiÃ³n + cobertura           |

---

# 8ï¸âƒ£ Si quisieras simplificar (opcional)

### Nivel bÃ¡sico

```python
retriever = vectorstore.as_retriever(search_type="similarity", k=3)
```

### Nivel intermedio (recomendado)

```python
retriever = MultiQueryRetriever.from_llm(
    retriever=vectorstore.as_retriever(search_type="mmr", k=3),
    llm=llm_queries,
)
```

### Nivel avanzado (tu caso actual)

âœ” Exactamente lo que tienes

---

## ðŸ ConclusiÃ³n

No es un lÃ­o, es una **estrategia en capas**:

> **Explorar bien â†’ no repetir â†’ no depender de una sola forma de preguntar â†’ combinar enfoques**

Esto es **arquitectura RAG madura**.
