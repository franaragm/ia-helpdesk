## 1ï¸âƒ£ Â¿QuÃ© hace realmente `@st.cache_resource`?

`cache_resource` estÃ¡ pensado para **objetos pesados y persistentes**:

* Conexiones
* Clientes
* Modelos
* Vectorstores
* Pipelines RAG completos

ğŸ‘‰ Se ejecuta **una sola vez por sesiÃ³n de Streamlit**, no por cada interacciÃ³n.

ğŸ“Œ Diferencia clave:

| Decorador           | Para quÃ©                          |
| ------------------- | --------------------------------- |
| `st.cache_data`     | Datos (listas, dicts, DataFrames) |
| `st.cache_resource` | Objetos vivos / costosos          |

---

## 2ï¸âƒ£ DÃ³nde SÃ usar `cache_resource` en tu proyecto

### ğŸŸ¢ A) Vectorstore (altamente recomendado)

Ahora mismo, cada vez que preguntas:

```python
vectorstore = get_vectorstore()
```

Eso:

* Reabre Chroma
* Reinstancia embeddings
* Relee metadata

ğŸ’¥ Innecesario

### âœ… SoluciÃ³n ideal

```python
# vectorstore.py
import streamlit as st

@st.cache_resource
def get_vectorstore() -> Chroma:
    return Chroma(
        embedding_function=OpenAIEmbeddings(model=EMBEDDING_MODEL),
        persist_directory=str(CHROMA_PATH),
        collection_name=COLLECTION_NAME,
    )
```

âœ” Se carga una vez
âœ” Se reutiliza en toda la sesiÃ³n
âœ” Mucho mÃ¡s rÃ¡pido

---

### ğŸŸ¢ B) Retriever completo

Tu `build_retriever()`:

* Crea MMR
* Crea MultiQuery
* Crea Ensemble

Todo eso **no cambia entre preguntas**.

### âœ… Muy buena candidata

```python
# retrievers.py
import streamlit as st

@st.cache_resource
def build_retriever() -> BaseRetriever:
    ...
```

Beneficio:

* No se reconstruye cada vez
* Menos llamadas al LLM de queries
* Comportamiento estable

---

### ğŸŸ¢ C) Pipeline RAG completo

Esto:

```python
rag_chain, retriever = build_rag_chain()
```

ğŸ‘‰ es **costoso** y **determinista**

### âœ… Ideal para cache_resource

```python
# rag.py
@st.cache_resource
def build_rag_chain():
    ...
```

Luego en `query_rag`:

```python
rag_chain, retriever = build_rag_chain()
```

Streamlit devolverÃ¡ el mismo objeto ya creado.

---

## 3ï¸âƒ£ DÃ³nde NO usar `cache_resource`

### ğŸ”´ A) `query_rag()`

âŒ NO

```python
@st.cache_resource
def query_rag(...):
```

Â¿Por quÃ©?

* La entrada (`question`) cambia
* CachearÃ­as respuestas equivocadas
* Memory leak potencial

---

### ğŸ”´ B) Funciones con estado mutable

Ejemplo peligroso:

```python
@st.cache_resource
def get_retriever():
    retriever.some_internal_state.append(...)
```

Si el objeto cambia internamente â†’ cache corrupta.

ğŸ“Œ En tu caso estÃ¡s bien: los retrievers son **inmutables**.

---

## 4ï¸âƒ£ RecomendaciÃ³n final para TU proyecto

### ğŸ¥‡ Nivel Ã³ptimo de caching

| Componente          | Decorador            |
| ------------------- | -------------------- |
| `get_vectorstore()` | `@st.cache_resource` |
| `build_retriever()` | `@st.cache_resource` |
| `build_rag_chain()` | `@st.cache_resource` |
| `query_rag()`       | âŒ NO                 |

---

## 5ï¸âƒ£ Ejemplo completo aplicado

```python
# retrievers.py
import streamlit as st

@st.cache_resource
def build_retriever() -> BaseRetriever:
    ...
```

```python
# rag.py
import streamlit as st

@st.cache_resource
def build_rag_chain():
    retriever = build_retriever()
    ...
    return rag_chain, retriever
```

---

## 6ï¸âƒ£ SeÃ±al de que lo estÃ¡s usando bien

âœ” La app no se â€œreiniciaâ€ en cada pregunta
âœ” Menos latencia tras la primera consulta
âœ” Logs de inicializaciÃ³n solo una vez

---

## ğŸ§  Regla mental rÃ¡pida

> **Â¿Este objeto es caro y no depende del input del usuario?**
> ğŸ‘‰ `cache_resource`

> **Â¿Depende del texto de la pregunta?**
> ğŸ‘‰ NO cachear

---
