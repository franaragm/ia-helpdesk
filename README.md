# ğŸ§ HELP DESK 2.0 CON IA (RAG)

## ğŸ“ DescripciÃ³n

Helpdesk inteligente basado en **Retrieval-Augmented Generation (RAG)**, especializado en soporte tÃ©cnico y consultas de usuarios.

El sistema permite:

* ğŸ” Recuperar informaciÃ³n relevante usando bÃºsqueda semÃ¡ntica avanzada.
* ğŸ¤– Generar respuestas fundamentadas en documentos internos indexados.
* ğŸ’¾ Mantener un **historial de tickets** y de pasos del procesamiento.
* ğŸ‘¨â€ğŸ’¼ Integrar un **flujo humano (Human-in-the-loop)** para escalado de consultas complejas.
* âœ… Control de confianza y fuentes consultadas.

EstÃ¡ diseÃ±ado con una arquitectura modular y extensible, pensado para **casos reales de soporte Helpdesk**.

![screenshot](readme_assets/screenshot.png)

![screenshot](readme_assets/screenshot-2.png)
---

## ğŸ Requisitos de Python

* Python 3.13.2 (recomendado, probado en macOS Apple Silicon y Windows)
* Python 3.11 (ideal para Mac Intel)

âš ï¸ No usar Python 3.14+, ya que rompe compatibilidad con:

* Pydantic
* ChromaDB
* LangChain Core

---

## ğŸ“‚ Estructura del proyecto

```
/ia-helpdesk/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ documents/              # Documentos de soporte iniciales (bootstrap opcional)
â”‚   â”œâ”€â”€ loader.py               # Carga PDFs y otros documentos, los divide en chunks
â”‚   â”œâ”€â”€ rag.py                  # OrquestaciÃ³n del pipeline RAG
â”‚   â”œâ”€â”€ retrievers.py           # ConstrucciÃ³n de retrievers (MMR, MultiQuery, Hybrid)
â”‚   â”œâ”€â”€ vectorstore.py          # CreaciÃ³n y carga del vectorstore Chroma (persistente)
â”‚   â”œâ”€â”€ prompts.py              # Prompts del sistema (RAG, clasificaciÃ³n)
â”‚   â”œâ”€â”€ schemas.py              # Modelos Pydantic (HelpdeskState, HelpdeskStateModel)
â”‚   â”œâ”€â”€ ui.py                   # Interfaz de usuario (Streamlit)
â”‚   â”œâ”€â”€ bootstrap.py            # InicializaciÃ³n segura de ChromaDB
â”‚   â”œâ”€â”€ constants.py            # Constantes, ejemplos de consultas
â”‚   â”œâ”€â”€ graph.py                # DefiniciÃ³n y compilaciÃ³n del grafo LangGraph
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ llm_client.py       # Clientes LLM (OpenAI, Google, OpenRouter)
â”‚       â””â”€â”€ utils.py            # Utilidades (hash, env vars, UUIDs, etc.)
â”œâ”€â”€ run_app.py                  # Punto de entrada de la aplicaciÃ³n
â”œâ”€â”€ config_base.py              # ConfiguraciÃ³n global (modelos, paths, RAG)
â”œâ”€â”€ requirements.txt            # Dependencias principales
â”œâ”€â”€ requirements.lock           # Dependencias fijadas
â””â”€â”€ .env                        # Variables de entorno
```

> Actualmente **no hay funcionalidad para subir nuevos documentos desde la UI**. Los documentos se cargan mediante `bootstrap.py` y desde el directorio `/documents` al iniciar la aplicaciÃ³n.

---

## ğŸ§  Arquitectura RAG (resumen)

### ğŸ”¹ InicializaciÃ³n (bootstrap)

Documentos en /documents â†’ load_documents() â†’ create_vectorstore() â†’ ChromaDB persistente en disco

> Solo se ejecuta si el vectorstore estÃ¡ vacÃ­o.

---

### ğŸ”¹ Flujo de consulta

Pregunta del usuario â†’ Nodo RAG (query_rag) â†’ Nodo ClasificaciÃ³n automÃ¡tica (auto vs escalado) â†’
Si es escalado â†’ Nodo humano (Human-in-the-loop) â†’ Nodo de generaciÃ³n de respuesta final â†’ Respuesta + historial + confianza + fuentes

* Cada nodo puede devolver **historial parcial** que se acumula.
* Si la consulta requiere intervenciÃ³n humana, la ejecuciÃ³n se pausa hasta que un agente responda.
* El estado final se valida con Pydantic antes de guardar en sesiÃ³n.

---

## ğŸš€ InstalaciÃ³n y uso

### ğŸ”§ 1) Crear entorno virtual

python -m venv .venv
source .venv/bin/activate      # macOS / Linux
.venv\Scripts\activate         # Windows

---

### ğŸ“¦ 2) Instalar dependencias

pip install -r requirements.txt
pip install -r requirements.lock

Para fijar nuevas dependencias:

pip freeze > requirements.lock

---

### ğŸ” 3) Configurar variables de entorno

cp .env.example .env

Editar `.env` con tus claves:

OPENAI_API_KEY=API_KEY_HERE
OPENROUTER_API_KEY=API_KEY_HERE
OPENROUTER_BASE_URL=[https://openrouter.ai/api/v1](https://openrouter.ai/api/v1)
ENV=dev

> Solo se usan las APIs que tengas configuradas; OpenAI y OpenRouter son opcionales segÃºn tu flujo.

---

### â–¶ï¸ 4) Ejecutar la aplicaciÃ³n

streamlit run run_app.py

Disponible en: [http://localhost:8501](http://localhost:8501)

---

## ğŸ–¥ï¸ Uso de la interfaz

### ğŸ’¬ Nueva consulta

* Escribe la consulta en el Ã¡rea de texto.
* Puedes elegir un ejemplo de consulta de la lista predefinida.
* Haz clic en **Enviar Consulta**.
* El sistema procesa la consulta paso a paso, mostrando el historial parcial.

### ğŸ« Tickets recientes

* En la columna derecha se muestran los tickets activos.
* Cada ticket muestra:

  * Usuario
  * Consulta
  * Historial de procesamiento
  * Confianza del RAG
  * Fuentes consultadas
* Si se requiere intervenciÃ³n humana:

  * Se puede escribir una respuesta manual
  * O usar la respuesta RAG como base

### ğŸ“Š EstadÃ­sticas (footer)

* Total de tickets
* Resueltos por RAG
* Resueltos por humano
* Pendientes

---

## ğŸ› ï¸ Desarrollo y extensibilidad

El proyecto estÃ¡ preparado para aÃ±adir:

* Filtrado o re-ranking avanzado
* ExtracciÃ³n de entidades (usuarios, fechas, IDs)
* Subida de nuevos documentos y reindexaciÃ³n incremental
* API REST con FastAPI
* Agentes personalizados o integraciÃ³n con otros flujos LangGraph

---

## ğŸ“Œ Notas importantes

* ChromaDB es **persistente** (no se pierde informaciÃ³n al reiniciar)
* IndexaciÃ³n incremental y segura
* Flujo de Human-in-the-loop implementado
* Evita duplicados en el vectorstore
* Historial de pasos accesible para cada ticket

---

## ğŸ“š Recursos

* LangChain â†’ [https://www.langchain.com/](https://www.langchain.com/)
* Streamlit â†’ [https://streamlit.io/](https://streamlit.io/)
* ChromaDB â†’ [https://www.trychroma.com/](https://www.trychroma.com/)
* Pydantic â†’ [https://docs.pydantic.dev/](https://docs.pydantic.dev/)

---

