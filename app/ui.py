import streamlit as st
from datetime import datetime
from .services.utils import generate_uuid
from .constants import HELPDESK_EXAMPLES
from .graph import compile_helpdesk
from .schemas import HelpdeskState, HelpdeskStateModel
from .bootstrap import init_chroma
from .vectorstore import get_vectorstore


# ======================================================
# ConfiguraciÃ³n de la pÃ¡gina
# ======================================================

st.set_page_config(
    page_title="Helpdesk 2.0 con RAG",
    page_icon="ğŸ§",
    layout="wide"
)

# ======================================================
# InicializaciÃ³n del estado de sesiÃ³n
# ======================================================
# Se crea UNA Ãºnica instancia del grafo con checkpointing
# y se mantiene viva durante toda la sesiÃ³n del usuario
if "helpdesk" not in st.session_state:
    st.session_state.helpdesk = compile_helpdesk()

if "tickets" not in st.session_state:
    st.session_state.tickets = {}
    
if "example_query" not in st.session_state:
    st.session_state.example_query = ""

# ======================================================
# Utilidades de configuraciÃ³n RAG
# ======================================================

def check_rag_setup() -> bool:
    """
    Verifica si el sistema RAG estÃ¡ correctamente configurado.
    
    - Intenta cargar el vectorstore persistido.
    - Comprueba que tenga documentos indexados.
    - Retorna True si el vectorstore funciona y contiene al menos un chunk.
    """
    try:
        with st.spinner("ğŸ” Verificando configuraciÃ³n RAG..."):
            # Cargar el vectorstore cacheado
            vectorstore = get_vectorstore()
            
            # Contar documentos/chunks indexados
            doc_count = len(vectorstore.get()["ids"])
            
            if doc_count == 0:
                st.warning("âš ï¸ Vectorstore OK pero no hay documentos indexados.")
                return False
            
            st.success(f"âœ… Vectorstore cargado correctamente. Documentos indexados: {doc_count}")
            return True
    
    except Exception as e:
        st.error(f"âŒ Error verificando RAG: {e}")
        return False


def configure_rag() -> bool:
    """
    Inicializa o actualiza ChromaDB de forma incremental.

    - Muestra un spinner mientras se ejecuta la indexaciÃ³n
    - Devuelve True si el proceso finaliza correctamente
    - Devuelve False si ocurre algÃºn error
    """
    try:
        with st.spinner("ğŸ”§ Configurando sistema RAG..."):
            init_chroma()
        return True
    except Exception as e:
        st.error(f"âŒ Error configurando RAG: {e}")
        return False


# ======================================================
# EjecuciÃ³n del grafo LangGraph
# ======================================================

def process_query(query: str, ticket_id: str) -> tuple[dict, list[str], dict]:
    """
    Ejecuta el grafo LangGraph usando streaming y checkpointing para procesar una consulta.

    Flujo del mÃ©todo:
    1. Se crea un estado inicial del helpdesk con la consulta del usuario.
    2. Se define un `thread_id` en la configuraciÃ³n para poder reanudar ejecuciones pausadas.
    3. Se itera sobre los eventos parciales del grafo (streaming).
       - Cada evento puede contener la salida de varios nodos.
       - Se acumula el historial explicativo de cada nodo.
    4. Se obtiene el estado final consolidado del grafo.
    5. Se devuelve:
       - `final_state.values`: el estado final en formato dict, listo para la UI.
       - `processing_history`: lista completa de pasos o logs del procesamiento.
       - `config`: configuraciÃ³n usada, Ãºtil para reanudar o actualizar el estado.

    ParÃ¡metros:
    - query (str): Texto de la consulta del usuario.
    - ticket_id (str): Identificador Ãºnico del ticket, usado como thread_id.

    Retorna:
    - Tuple[dict, List[str], dict]: (estado final, historial completo, configuraciÃ³n)
    """

    # ================================
    # 1. Crear el estado inicial
    # ================================
    initial_state = HelpdeskState(
        query=query,                # Consulta original
        category=None,              # CategorÃ­a del ticket (automÃ¡tica o escalada)
        rag_answer=None,            # Respuesta generada por RAG
        confidence=0.0,             # Confianza heurÃ­stica
        sources=[],                 # Fuentes consultadas
        rag_context=None,           # Contexto textual usado por RAG
        requires_human=False,       # Flag si necesita intervenciÃ³n humana
        human_answer=None,          # Respuesta del humano si aplica
        final_answer=None,          # Respuesta final consolidada
        history=[]                  # Historial explicativo del flujo
    )

    # ================================
    # 2. ConfiguraciÃ³n para checkpointing
    # ================================
    # `thread_id` permite pausar y reanudar la ejecuciÃ³n del grafo
    config = {"configurable": {"thread_id": ticket_id}}

    # Lista donde vamos a acumular todo el historial de pasos del grafo
    processing_history: list[str] = []

    try:
        # ================================
        # 3. Streaming de actualizaciones del grafo
        # ================================
        # El mÃ©todo stream() devuelve un iterable de stream_event
        # Cada stream_event es un dict {nodo: salida_parcial}
        # Esto permite mostrar progresos en tiempo real si quisiÃ©ramos
        for stream_event in st.session_state.helpdesk.stream(
            initial_state,
            config=config,
            stream_mode="updates"  # streaming parcial, recibe eventos a medida que se generan
        ):
            # Cada evento puede contener la salida de varios nodos
            for node, node_output in stream_event.items():
                # Si el nodo devuelve historial, se acumula en processing_history
                if "history" in node_output and node_output["history"]:
                    processing_history.extend(node_output["history"])

         # ================================
        # 4. Obtener estado final consolidado
        # ================================
        # El objeto final_state contiene TODO el estado interno del grafo:
        # - Valores de HelpdeskState
        # - Metadata interna
        # - Checkpoints, referencias a nodos, etc.
        final_state = st.session_state.helpdesk.get_state(config)
        
        # ================================
        # 5. Validar con Pydantic
        # ================================
        # final_state.values -> Diccionario limpio con solo los campos de HelpdeskState
        # Esto es seguro para guardar en st.session_state.tickets y mostrar en la UI
        validated_final_state = HelpdeskStateModel(**final_state.values).model_dump(exclude_none=True)


        # ================================
        # 6. Retornar resultados
        # ================================
        return validated_final_state, processing_history, config

    except Exception as e:
        # Cualquier error se muestra en la UI y retornamos valores vacÃ­os
        st.error(f"âŒ Error procesando consulta: {str(e)}")
        return None, [], None

# ======================================================
# ReanudaciÃ³n grafo tras intervenciÃ³n humana
# ======================================================

def resume_with_human_answer(ticket_config: dict, human_answer: str,) -> tuple[dict, list[str]]:
    """
    Reanuda la ejecuciÃ³n del grafo LangGraph tras una intervenciÃ³n humana.

    Flujo:
    1. Inyecta la respuesta del agente humano en el estado existente.
    2. Reanuda el grafo desde el Ãºltimo checkpoint (antes de process_human).
    3. Consume los eventos de streaming restantes.
    4. Devuelve el estado final validado y el historial generado.
    """

    resumed_history: list[str] = []

    try:
        # ================================
        # 1ï¸âƒ£ Actualizar el estado del grafo con la respuesta humana
        # ================================
        # Inyectamos la respuesta escrita por el agente en el estado del grafo
        # `ticket_config` permite identificar el thread/ticket correcto
        # Esto es lo que hace que el flujo pueda continuar desde donde se pausÃ³
        st.session_state.helpdesk.update_state(
            ticket_config,
            {"human_answer": human_answer},
        )

        # ================================
        # 2ï¸âƒ£ Reanudar el procesamiento del grafo desde el punto de interrupciÃ³n
        # ================================
        # El mÃ©todo stream() permite ejecutar nodos pendientes
        # pasando None como estado inicial porque ya tenemos el checkpoint
        # stream_mode="updates" devuelve eventos parciales (historial) mientras se ejecuta
        for stream_event in st.session_state.helpdesk.stream(
            None,  # None indica "continÃºa desde el Ãºltimo estado guardado"
            config=ticket_config,
            stream_mode="updates",
        ):  
            # Cada event puede contener la salida de varios nodos
            for _, node_output in stream_event.items():
                # Si el nodo devuelve historial de pasos, lo aÃ±adimos al ticket
                if node_output.get("history"):
                    resumed_history.extend(node_output["history"])

        # ================================
        # 3ï¸âƒ£ Obtener el estado final consolidado del grafo
        # ================================
        # final_state contiene todo el estado interno
        # final_state.values -> solo los campos definidos en HelpdeskState
        final_state = st.session_state.helpdesk.get_state(ticket_config)

        # ================================
        # 4ï¸âƒ£ Validar y guardar el estado final
        # ================================
        # Se valida con Pydantic para asegurar consistencia
        # model_dump(exclude_none=True) elimina campos vacÃ­os para mantener el estado limpio
        validated_state = (
            HelpdeskStateModel(**final_state.values)
            .model_dump(exclude_none=True)
        )

        return validated_state, resumed_history

    except Exception as e:
        st.error(f"âŒ Error reanudando ejecuciÃ³n con respuesta humana: {e}")
        return {}, []


# ======================================================
# AplicaciÃ³n principal
# ======================================================

def main():
    """UI principal del sistema Helpdesk."""

    st.title("ğŸ§ Helpdesk 2.0 con RAG + ChromaDB")
    st.markdown("*Sistema inteligente con LangGraph y bÃºsqueda vectorial*")

    # Verificar estado del sistema RAG
    is_rag_configured = check_rag_setup()

    # ==================================================
    # Sidebar
    # ==================================================
    with st.sidebar:
        st.header("ğŸ“Š Panel de Control")
        st.metric("Tickets Activos", len(st.session_state.tickets))

        # Estado del sistema RAG
        st.subheader("ğŸ” Estado RAG")
        if is_rag_configured:
            st.success("âœ… ChromaDB configurado")
            if st.button("ğŸ”„ Reconfigurar RAG"):
                if configure_rag():
                    st.success("âœ… RAG reconfigurado")
                    st.rerun()
                else:
                    st.error("âŒ Error reconfigurando RAG")
        else:
            st.warning("âš ï¸ RAG no configurado")
            if st.button("ğŸš€ Configurar RAG"):
                if configure_rag():
                    st.success("âœ… RAG configurado exitosamente")
                    st.rerun()
                else:
                    st.error("âŒ Error configurando RAG")

        st.subheader("ğŸ”„ Flujo del Sistema")
        st.text(
            """
            1. ğŸ“ Usuario envÃ­a consulta
            2. ğŸ¤– ClasificaciÃ³n automÃ¡tica
            3. ğŸ” BÃºsqueda vectorial RAG
            4. ğŸ“Š EvaluaciÃ³n de confianza
            5. ğŸ‘¨â€ğŸ’¼ Escalado si es necesario
            6. âœ… Respuesta final
            """
        )

        st.subheader("âš™ï¸ ConfiguraciÃ³n")
        if st.button("ğŸ—‘ï¸ Limpiar Tickets"):
            st.session_state.tickets = {}
            st.rerun()

    if not is_rag_configured:
        st.warning(
            "âš ï¸ El sistema RAG no estÃ¡ configurado. "
            "Usa el botÃ³n en la barra lateral para configurarlo."
        )
        return

    # ==================================================
    # Ãrea principal
    # ==================================================
    col1, col2 = st.columns([1, 1])

    # ==================================================
    # Nueva consulta
    # ==================================================
    with col1:
        st.subheader("ğŸ“ Nueva Consulta")

        # Selectbox para elegir ejemplo
        selected_example = st.selectbox(
            "ğŸ’¡ Elige un ejemplo de consulta o deja vacÃ­o para escribir la tuya",
            options=[""] + HELPDESK_EXAMPLES,
            index=0
        )

        # Guardar selecciÃ³n en sesiÃ³n
        if selected_example:
            st.session_state.example_query = selected_example

        with st.form("new_query"):
            user = st.text_input("ğŸ‘¤ Usuario", placeholder="tu@email.com")

            initial_query = st.session_state.get("example_query", "")
            query = st.text_area(
                "ğŸ’¬ DescripciÃ³n del problema",
                value=initial_query,
                placeholder="Describe tu consulta o problema aquÃ­...",
                height=100
            )

            submitted = st.form_submit_button("ğŸš€ Enviar Consulta")

            if submitted and query.strip():
                if "example_query" in st.session_state:
                    del st.session_state.example_query

                ticket_id = generate_uuid()

                with st.spinner("ğŸ”„ Procesando consulta..."):
                    result, history, config = process_query(query, ticket_id)

                if result:
                    st.session_state.tickets[ticket_id] = {
                        "user": user,
                        "query": query,
                        "result": result,
                        "history": history,
                        "config": config,
                        "timestamp": datetime.now().strftime("%H:%M:%S"),
                    }

                    st.success(f"âœ… Ticket {ticket_id} creado")
                    st.rerun()
                    
    # ==================================================
    # Tickets recientes
    # ==================================================
    with col2:
        st.subheader("ğŸ« Tickets Recientes")

        if not st.session_state.tickets:
            st.info("No hay tickets activos")
        else:
            # Mostrar tickets mÃ¡s recientes primero
            # `st.session_state.tickets` es un dict que mantiene el orden de inserciÃ³n.
            # `.items()` devuelve pares (ticket_id, ticket_data) en orden de creaciÃ³n.
            # `list(...)` permite invertir el orden, ya que los iteradores no son reversibles.
            # `reversed(...)` hace que los tickets mÃ¡s recientes se muestren primero en la UI.
            for ticket_id, ticket_data in reversed(list(st.session_state.tickets.items())):
                with st.expander(f"ğŸ« {ticket_id} - {ticket_data['timestamp']}", expanded=False):

                    st.markdown(f"**ğŸ‘¤ Usuario:** {ticket_data.get('user', 'â€”')}")
                    st.markdown(f"**ğŸ’¬ Consulta:** {ticket_data['query']}")

                    result = ticket_data["result"]
                    history = ticket_data["history"]

                    # ----------------------------
                    # Historial de procesamiento
                    # ----------------------------
                    if history:
                        st.subheader("ğŸ”„ Procesamiento")
                        for step in history:
                            st.text(step)

                    # ----------------------------
                    # ClasificaciÃ³n
                    # ----------------------------
                    if result.get("category"):
                        st.markdown(f"**ğŸ“‚ CategorÃ­a:** {result['category']}")

                    # ----------------------------
                    # InformaciÃ³n RAG
                    # ----------------------------
                    confidence = result.get("confidence", 0.0)
                    if confidence > 0:
                        st.markdown(f"**ğŸ¯ Confianza RAG:** {confidence:.2f}")
                        st.progress(confidence)

                        if result.get("sources"):
                            st.markdown(
                                f"**ğŸ“š Fuentes:** {', '.join(result['sources'])}"
                            )

                    # ----------------------------
                    # Human-in-the-loop: intervenciÃ³n humana
                    # ----------------------------
                    if result.get("requires_human") and not result.get("final_answer"):
                        st.warning("ğŸ‘¨â€ğŸ’¼ Requiere intervenciÃ³n humana")

                        if result.get("rag_answer"):
                            with st.expander("ğŸ“‹ Contexto RAG"):
                                st.text(result["rag_answer"])

                        human_reply = st.text_area(
                            "âœï¸ Respuesta del agente",
                            key=f"human_{ticket_id}",
                            height=100,
                            placeholder="Escribe la respuesta para el usuario..."
                        )

                        col_btn1, col_btn2 = st.columns(2)

                        with col_btn1:
                            if st.button("ğŸ’¾ Enviar Respuesta", key=f"send_{ticket_id}"):
                                if human_reply.strip():
                                    config = ticket_data["config"]
                                    
                                    # Actualizar el estado con la respuesta humana
                                    result, history = resume_with_human_answer(config, human_reply)
                                    ticket_data["result"] = result
                                    ticket_data["history"].extend(history)

                                    st.success("âœ… Respuesta enviada")
                                    st.rerun()
                                else:
                                    st.warning("âš ï¸ Escribe una respuesta antes de enviar")

                        with col_btn2:
                            if st.button("ğŸ¤– Usar RAG", key=f"rag_{ticket_id}"):
                                config = ticket_data["config"]
                                
                                # Reutilizamos el mismo flujo que para el humano,
                                # pero pasando la respuesta RAG como si fuera la "humana"
                                result, history = resume_with_human_answer(
                                    ticket_config=config,
                                    human_answer=result.get("rag_answer", "")
                                )
                                ticket_data["result"] = result
                                ticket_data["history"].extend(history)

                                st.success("âœ… Respuesta RAG aplicada")
                                st.rerun()

                    # ----------------------------
                    # Respuesta final
                    # ----------------------------
                    elif result.get("final_answer"):
                        st.success("âœ… Ticket Resuelto")
                        st.markdown("**ğŸ’¬ Respuesta final:**")
                        
                        # Mostrar respuesta final
                        st.info(result["final_answer"])

                        # MÃ©tricas finales
                        col_m1, col_m2, col_m3 = st.columns(3)
                        with col_m1:
                            st.metric("ğŸ¯ Confianza", f"{confidence:.2f}")
                        with col_m2:
                            st.metric("ğŸ“š Fuentes", len(result.get("sources", [])))
                        with col_m3:
                            resolver = "Humano" if result.get("requires_human") else "RAG"
                            st.metric("ğŸ¤– Resuelto por", resolver)

    # ==================================================
    # Footer con estadÃ­sticas
    # ==================================================
    st.markdown("---")

    if st.session_state.tickets:
        total = len(st.session_state.tickets)

        resolved_rag = sum(
            1 for t in st.session_state.tickets.values()
            if t["result"].get("final_answer") and not t["result"].get("requires_human")
        )

        resolved_human = sum(
            1 for t in st.session_state.tickets.values()
            if t["result"].get("final_answer") and t["result"].get("requires_human")
        )

        pending = total - resolved_rag - resolved_human

        col_s1, col_s2, col_s3, col_s4 = st.columns(4)
        with col_s1:
            st.metric("ğŸ“Š Total Tickets", total)
        with col_s2:
            st.metric("ğŸ¤– Resueltos por RAG", resolved_rag)
        with col_s3:
            st.metric("ğŸ‘¨â€ğŸ’¼ Resueltos por Humano", resolved_human)
        with col_s4:
            st.metric("â³ Pendientes", pending)

    st.markdown(
        """
        <div style='text-align: center'>
            <small>
                ğŸš€ Powered by LangGraph Â· ğŸ” ChromaDB Â· ğŸ”„ Streaming Â· ğŸ’¾ Checkpointing Â· ğŸ‘¨â€ğŸ’¼ Human-in-the-Loop
            </small>
        </div>
        """,
        unsafe_allow_html=True
    )
